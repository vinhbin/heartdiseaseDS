{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a657be51-fc0e-4e82-96b3-4b9e3743df4c",
   "metadata": {},
   "source": [
    "> ### ðŸ—“ï¸ **Project Deadlines**\n",
    "> - **November 21, December 2, December 4:** Presentations  \n",
    "> - **December 8 (11:00 PM):** Final report submission  \n",
    ">\n",
    "> ---\n",
    ">\n",
    "> ### ðŸ§  **Brainstorming & Project Development**\n",
    "> Dataset source: [UCI Heart Disease Dataset](https://archive.ics.uci.edu/dataset/45/heart+disease)\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> ### ðŸ“Š **Dataset Information**\n",
    "> - The database contains **76 attmributes**, but all published experiments use a **subset of 14**.  \n",
    "> - The **Cleveland database** is the one most commonly used in ML research.  \n",
    "> - The **goal** field indicates **heart disease presence**:\n",
    ">   - `0` = no disease  \n",
    ">   - `1, 2, 3, 4` = disease present  \n",
    "> - Most studies simplify this into **binary classification**:  \n",
    ">   - 0 â†’ No Heart Disease  \n",
    ">   - 1 â†’ Heart Disease Present  \n",
    "> - Personally identifiable information (like names/SSNs) has been **removed** and replaced with dummy values.  \n",
    "> - The **\"processed\" file** corresponds to the **Cleveland dataset**, which weâ€™ll use.  \n",
    ">\n",
    "> ---\n",
    ">\n",
    "> > ### ðŸ§¹ **Data Cleaning Plan**\n",
    ">\n",
    "> #### 1ï¸âƒ£ Replace or Drop Missing Values\n",
    "> - In this dataset, missing values are represented by `?`.  \n",
    "> - Weâ€™ll replace them with `NaN` and decide whether to drop or impute them later.  \n",
    ">   ```python\n",
    ">   df.replace('?', pd.NA, inplace=True)\n",
    ">   df = df.dropna()\n",
    ">   ```\n",
    ">   ðŸ§  *Ensures all numeric data is valid before processing.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 2ï¸âƒ£ Convert All Columns to Correct Data Types\n",
    "> - After replacing `?`, columns may still be stored as `object`.  \n",
    ">   ```python\n",
    ">   df = df.apply(pd.to_numeric)\n",
    ">   ```\n",
    ">   ðŸ§  *Allows models and numerical operations to work correctly.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 3ï¸âƒ£ Simplify the Target Variable\n",
    "> - The `target` column values range from 0â€“4.  \n",
    "> - Convert to a **binary classification**:  \n",
    ">   ```python\n",
    ">   df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    ">   ```\n",
    ">   ðŸ§  *Groups all levels of heart disease into a single â€œdisease presentâ€ category.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 4ï¸âƒ£ Check for Duplicate Records\n",
    "> - Remove duplicates to prevent bias.  \n",
    ">   ```python\n",
    ">   df = df.drop_duplicates()\n",
    ">   ```\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 5ï¸âƒ£ Detect Outliers or Unrealistic Values\n",
    "> - Use summary stats or boxplots to spot extreme values (e.g., cholesterol = 0).  \n",
    ">   ```python\n",
    ">   df.describe()\n",
    ">   ```\n",
    ">   ðŸ§  *Outliers may affect model accuracy â€” decide to clip or scale later.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 6ï¸âƒ£ Feature Scaling / Normalization\n",
    "> - Standardize features so theyâ€™re on a similar scale.  \n",
    ">   ```python\n",
    ">   from sklearn.preprocessing import StandardScaler\n",
    ">   scaler = StandardScaler()\n",
    ">   X_scaled = scaler.fit_transform(df.drop('target', axis=1))\n",
    ">   ```\n",
    ">   ðŸ§  *Prevents large-scale features (like cholesterol) from dominating small ones.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 7ï¸âƒ£ Encode Categorical Features\n",
    "> - Columns like `cp`, `thal`, and `slope` represent categories, not numeric values.  \n",
    ">   ```python\n",
    ">   df = pd.get_dummies(df, columns=['cp', 'thal', 'slope'], drop_first=True)\n",
    ">   ```\n",
    ">   ðŸ§  *One-hot encoding helps algorithms correctly interpret these features.*\n",
    ">\n",
    "> ---\n",
    ">\n",
    "> #### 8ï¸âƒ£ Final Sanity Checks\n",
    "> ```python\n",
    "> df.info()\n",
    "> df.isnull().sum()\n",
    "> df.head()\n",
    "> ```\n",
    "> ðŸ§  *Confirm:*\n",
    "> - No missing values  \n",
    "> - Correct data types  \n",
    "> - Logical column outputs  \n",
    ">\n",
    "> ---\n",
    ">\n",
    "> âœ… **After this step:**  \n",
    "> The dataset will be fully cleaned, numeric, and ready for **EDA** (Exploratory Data Analysis) and **Model Building**.\n",
    "\n",
    ">\n",
    "> âœ… **Summary**\n",
    "> Weâ€™ll use the **Cleveland Heart Disease dataset**, clean the missing values, add headers, and then proceed with exploratory analysis and prediction modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e0739e-ce72-4380-90f8-cd9ff4b2ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca  thal  target  \n",
       "0    3.0  0.0   6.0       0  \n",
       "1    2.0  3.0   3.0       2  \n",
       "2    2.0  2.0   7.0       1  \n",
       "3    3.0  0.0   3.0       0  \n",
       "4    1.0  0.0   3.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#defining column names\n",
    "cols = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs',\n",
    "    'restecg', 'thalach', 'exang', 'oldpeak', 'slope',\n",
    "    'ca', 'thal', 'target'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\"data/processed.cleveland.data\", names=cols, na_values='?')\n",
    "\n",
    "# Preview first few rows\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f84b0235-0ac9-4f2d-acf3-fe9c3d6fdef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values before cleaning:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "data types after conversion:\n",
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca          float64\n",
      "thal        float64\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# cleaning the data\n",
    "\n",
    "print(\"missing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "#dropping rows with missing values for simplicity\n",
    "df = df.dropna()\n",
    "\n",
    "#converting all columns to numeric data types\n",
    "df = df.apply(pd.to_numeric)\n",
    "\n",
    "print(\"\\ndata types after conversion:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0095d60a-141e-4df1-af5e-2b68a36c0652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "value counts for target column:\n",
      "target\n",
      "0    160\n",
      "1    137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# simplifying target column (binary classification)\n",
    "# original: 0 = no disease, 1-4 = presence of disease\n",
    "df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "print(\"\\nvalue counts for target column:\")\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56d453ea-5f27-4909-92b9-ce6e5e442c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "after removing duplicates:\n",
      "(297, 14)\n",
      "\n",
      "summary statistics:\n",
      "              age         sex          cp    trestbps        chol         fbs  \\\n",
      "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
      "mean    54.542088    0.676768    3.158249  131.693603  247.350168    0.144781   \n",
      "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
      "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
      "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
      "50%     56.000000    1.000000    3.000000  130.000000  243.000000    0.000000   \n",
      "75%     61.000000    1.000000    4.000000  140.000000  276.000000    0.000000   \n",
      "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
      "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
      "mean     0.996633  149.599327    0.326599    1.055556    1.602694    0.676768   \n",
      "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
      "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
      "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
      "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
      "\n",
      "             thal      target  \n",
      "count  297.000000  297.000000  \n",
      "mean     4.730640    0.461279  \n",
      "std      1.938629    0.499340  \n",
      "min      3.000000    0.000000  \n",
      "25%      3.000000    0.000000  \n",
      "50%      3.000000    0.000000  \n",
      "75%      7.000000    1.000000  \n",
      "max      7.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# removing dups and basic sanity checks\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#verify\n",
    "print(\"\\nafter removing duplicates:\")\n",
    "print(df.shape)\n",
    "\n",
    "#quick summary\n",
    "print(\"\\nsummary statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0085d48b-001c-4979-bfd3-91167a902a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "final dataset info:\n",
      "\n",
      "missing values after cleaning:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "data cleaning is complete. ready for eda or modeling\n"
     ]
    }
   ],
   "source": [
    "#final check - were getting ready for EDA or modeling\n",
    "\n",
    "print(\"\\nfinal dataset info:\")\n",
    "df.info\n",
    "\n",
    "print(\"\\nmissing values after cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\ndata cleaning is complete. ready for eda or modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbba1ba-d6b5-44ba-8f3e-22b60a879de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
