{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3484127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e03c85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  ...  oldpeak  slope   ca  thal  target\n",
       "0  63.0  1.0  1.0     145.0  233.0  ...      2.3    3.0  0.0   6.0       0\n",
       "1  67.0  1.0  4.0     160.0  286.0  ...      1.5    2.0  3.0   3.0       1\n",
       "2  67.0  1.0  4.0     120.0  229.0  ...      2.6    2.0  2.0   7.0       1\n",
       "3  37.0  1.0  3.0     130.0  250.0  ...      3.5    3.0  0.0   3.0       0\n",
       "4  41.0  0.0  2.0     130.0  204.0  ...      1.4    1.0  0.0   3.0       0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading cleaned data\n",
    "df = pd.read_csv(\"cleaned_processed.cleveland.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e934b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((237, 13), (60, 13), (237,), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test: split data\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce369bed",
   "metadata": {},
   "source": [
    "## Training Models: Heart Disease Prediction\n",
    "\n",
    "### Overview\n",
    "We will train and evaluate multiple machine learning models to predict heart disease presence. Our approach:\n",
    "\n",
    "1. **Baseline Model**: Logistic Regression - Simple, interpretable, and effective for binary classification\n",
    "2. **Tree-Based Models**: Decision Tree and Random Forest - Capture non-linear relationships\n",
    "3. **Support Vector Machine**: Finds optimal decision boundary in high-dimensional space\n",
    "4. **k-Nearest Neighbors**: Instance-based learning approach\n",
    "\n",
    "### Evaluation Metrics\n",
    "For each model, we'll track:\n",
    "- **Accuracy**: Overall correctness of predictions\n",
    "- **Precision**: Of predicted disease cases, how many are correct? (Important to avoid false alarms)\n",
    "- **Recall**: Of actual disease cases, how many did we catch? (Critical in medical diagnosis)\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "- **ROC-AUC**: Model's ability to distinguish between classes\n",
    "\n",
    "### Why These Metrics Matter in Healthcare\n",
    "- **High Recall** is crucial: Missing a disease case (false negative) can be life-threatening\n",
    "- **Balanced Precision**: Too many false positives lead to unnecessary tests and patient anxiety\n",
    "- **ROC-AUC**: Helps us understand model performance across different decision thresholds\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5dd6e",
   "metadata": {},
   "source": [
    "## Model A: Logistic Regression (Baseline)\n",
    "\n",
    "### What is Logistic Regression?\n",
    "Logistic Regression is a statistical model that predicts the probability of a binary outcome (disease/no disease). Despite its name, it's a **classification** algorithm, not regression.\n",
    "\n",
    "### How It Works\n",
    "1. **Linear Combination**: Combines features using weights (coefficients): `z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô + b`\n",
    "2. **Sigmoid Function**: Transforms z into a probability between 0 and 1: `P(disease) = 1 / (1 + e^(-z))`\n",
    "3. **Decision Boundary**: If P > 0.5, predict disease; otherwise, no disease\n",
    "\n",
    "### Why Start with Logistic Regression?\n",
    "‚úÖ **Interpretable**: Each coefficient shows feature importance and direction of effect  \n",
    "‚úÖ **Fast**: Trains quickly, even on large datasets  \n",
    "‚úÖ **Probabilistic**: Provides confidence scores, not just predictions  \n",
    "‚úÖ **Baseline**: Establishes performance benchmark for more complex models  \n",
    "‚úÖ **Clinically Relevant**: Doctors can understand which factors drive predictions  \n",
    "\n",
    "### Key Assumptions\n",
    "- Features should be relatively independent (low multicollinearity)\n",
    "- Linear relationship between features and log-odds of outcome\n",
    "- Benefits from feature scaling (which we'll apply)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_scaling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling - Critical for Logistic Regression\n",
    "# Standardization: transforms features to have mean=0 and std=1\n",
    "# This ensures all features contribute equally to the model\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Original feature ranges (first 3 features):\")\n",
    "print(f\"Age: {X_train['age'].min():.1f} to {X_train['age'].max():.1f}\")\n",
    "print(f\"Sex: {X_train['sex'].min():.1f} to {X_train['sex'].max():.1f}\")\n",
    "print(f\"Chest Pain: {X_train['cp'].min():.1f} to {X_train['cp'].max():.1f}\")\n",
    "\n",
    "print(\"\\nAfter scaling (mean ‚âà 0, std ‚âà 1):\")\n",
    "print(f\"Age: {X_train_scaled[:, 0].mean():.3f} ¬± {X_train_scaled[:, 0].std():.3f}\")\n",
    "print(f\"Sex: {X_train_scaled[:, 1].mean():.3f} ¬± {X_train_scaled[:, 1].std():.3f}\")\n",
    "print(f\"Chest Pain: {X_train_scaled[:, 2].mean():.3f} ¬± {X_train_scaled[:, 2].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model\n",
    "log_reg = LogisticRegression(\n",
    "    random_state=42,      # For reproducibility\n",
    "    max_iter=1000,        # Maximum iterations for convergence\n",
    "    solver='lbfgs'        # Optimization algorithm\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = log_reg.predict(X_train_scaled)\n",
    "y_pred_test = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Get prediction probabilities (for ROC curve)\n",
    "y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"‚úì Model trained successfully!\")\n",
    "print(f\"\\nModel intercept: {log_reg.intercept_[0]:.4f}\")\n",
    "print(f\"Number of features: {len(log_reg.coef_[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - MODEL PERFORMANCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training Set Performance\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f\"\\nüìä Training Set Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Test Set Performance\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_precision = precision_score(y_test, y_pred_test)\n",
    "test_recall = recall_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test)\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"   Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"   Precision: {test_precision:.4f} ({test_precision*100:.2f}%)\")\n",
    "print(f\"   Recall:    {test_recall:.4f} ({test_recall*100:.2f}%)\")\n",
    "print(f\"   F1-Score:  {test_f1:.4f}\")\n",
    "print(f\"   ROC-AUC:   {test_roc_auc:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "overfit_gap = train_accuracy - test_accuracy\n",
    "print(f\"\\nüîç Overfitting Check:\")\n",
    "print(f\"   Train-Test Gap: {overfit_gap:.4f}\")\n",
    "if overfit_gap < 0.05:\n",
    "    print(\"   ‚úì Good generalization - minimal overfitting\")\n",
    "elif overfit_gap < 0.10:\n",
    "    print(\"   ‚ö† Slight overfitting - acceptable\")\n",
    "else:\n",
    "    print(\"   ‚úó Significant overfitting - model may not generalize well\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_confusion_matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix Analysis\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nüìã Confusion Matrix Breakdown:\")\n",
    "print(f\"\\n                 Predicted\")\n",
    "print(f\"               No Disease  Disease\")\n",
    "print(f\"Actual No Dis      {tn:3d}       {fp:3d}\")\n",
    "print(f\"       Disease     {fn:3d}       {tp:3d}\")\n",
    "\n",
    "print(f\"\\nüéØ Interpretation:\")\n",
    "print(f\"   True Negatives (TN):  {tn} - Correctly identified healthy patients\")\n",
    "print(f\"   True Positives (TP):  {tp} - Correctly identified disease patients\")\n",
    "print(f\"   False Positives (FP): {fp} - Healthy patients misclassified as diseased\")\n",
    "print(f\"   False Negatives (FN): {fn} - Disease patients missed (most critical!)\")\n",
    "\n",
    "print(f\"\\n‚öïÔ∏è Clinical Implications:\")\n",
    "print(f\"   ‚Ä¢ {fn} patients with disease were not detected\")\n",
    "print(f\"   ‚Ä¢ {fp} healthy patients would undergo unnecessary follow-up\")\n",
    "print(f\"   ‚Ä¢ Detection rate: {(tp/(tp+fn)*100):.1f}% of disease cases caught\")\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Disease', 'Disease'],\n",
    "            yticklabels=['No Disease', 'Disease'],\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Logistic Regression - Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_roc_curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve - Model Discrimination Ability\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2.5, \n",
    "         label=f'Logistic Regression (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "         label='Random Classifier (AUC = 0.500)')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (Recall)', fontsize=12)\n",
    "plt.title('ROC Curve - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà ROC-AUC Score: {roc_auc:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "if roc_auc >= 0.90:\n",
    "    print(\"   ‚≠ê Excellent discrimination ability\")\n",
    "elif roc_auc >= 0.80:\n",
    "    print(\"   ‚úì Good discrimination ability\")\n",
    "elif roc_auc >= 0.70:\n",
    "    print(\"   ‚óã Acceptable discrimination ability\")\n",
    "else:\n",
    "    print(\"   ‚úó Poor discrimination ability\")\n",
    "    \n",
    "print(f\"\\nThe model is {((roc_auc - 0.5) / 0.5 * 100):.1f}% better than random guessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lr_feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "# Coefficients show the impact of each feature on disease prediction\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nüîç Feature Importance (Top 10):\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    direction = \"‚Üë Increases\" if row['Coefficient'] > 0 else \"‚Üì Decreases\"\n",
    "    print(f\"{row['Feature']:12s} | {row['Coefficient']:7.4f} | {direction} disease risk\")\n",
    "\n",
    "# Visualize Feature Importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['#d62728' if x < 0 else '#2ca02c' for x in feature_importance['Coefficient']]\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, alpha=0.8)\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Logistic Regression - Feature Importance\\n(Green = Risk Factor, Red = Protective Factor)', \n",
    "          fontsize=13, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lr_summary",
   "metadata": {},
   "source": [
    "### üìä Logistic Regression Summary\n",
    "\n",
    "#### Key Findings:\n",
    "1. **Strong Performance**: Achieved ~88% accuracy with excellent ROC-AUC (~0.93)\n",
    "2. **No Overfitting**: Similar performance on training and test sets\n",
    "3. **High Recall**: Successfully identifies most disease cases (87.5%)\n",
    "4. **Interpretable**: Clear understanding of which features drive predictions\n",
    "\n",
    "#### Most Important Predictors:\n",
    "- **ca** (major vessels): Strongest predictor - more blockages = higher risk\n",
    "- **sex**: Males at significantly higher risk\n",
    "- **trestbps**: Higher blood pressure correlates with disease\n",
    "- **oldpeak**: ST depression indicates ischemia\n",
    "- **thalach**: Higher max heart rate is protective (negative coefficient)\n",
    "\n",
    "#### Clinical Relevance:\n",
    "‚úÖ **Strengths**:\n",
    "- Fast predictions suitable for real-time screening\n",
    "- Provides probability scores for risk stratification\n",
    "- Doctors can understand and trust the reasoning\n",
    "- Low false negative rate (only 3 missed cases)\n",
    "\n",
    "‚ö†Ô∏è **Limitations**:\n",
    "- Assumes linear relationships (may miss complex patterns)\n",
    "- 4 false positives (unnecessary follow-ups)\n",
    "- 3 false negatives (missed diagnoses - most critical)\n",
    "\n",
    "#### Next Steps:\n",
    "Compare with more complex models (Decision Tree, Random Forest, SVM) to see if we can:\n",
    "- Reduce false negatives (improve recall)\n",
    "- Capture non-linear relationships\n",
    "- Improve overall accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0524007",
   "metadata": {},
   "source": [
    "Model B: Decision Tree\n",
    "\n",
    "blah blah explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754b7b17",
   "metadata": {},
   "source": [
    "Model C: Random Forest\n",
    "\n",
    "blah blah explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afc2c4",
   "metadata": {},
   "source": [
    "Model D: Support Vector Machine\n",
    "\n",
    "blah blah explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4f895",
   "metadata": {},
   "source": [
    "Model E: kNN\n",
    "\n",
    "blah blah explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
